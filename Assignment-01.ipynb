{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年05月13日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 无人驾驶，图像识别，机器翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:   \n",
    "+ 讲自己的作业代码上传到自己的GitHub，方便老师、学员间互相交流作业、代码，互相学习借鉴得到提高；  \n",
    "+ Jupyter集实时代码、可视化、解释性文档撰写等功能于一身，十分适合初学者进行统计建模与机器学习的学习；  \n",
    "+ Pycharm是功能十分强大的Python编译器，提供了代码分析、图形化调试器、版本控制等功能，适合各种大型项目的开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 在自然语言处理中，概率模型是一种利用统计方法来计算某个词或某个句子出现概率的数学模型，来指导人们判断处理结果是否合理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 搜索引擎或邮件系统中的自动补全；\n",
    "+ 文本处理中的自动拼写检查。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 自然语言处理中，使用概率能够非常好地利用到已有语料库的先验信息，概率模型也是一种简单便捷且有效的自然语言处理方法；\n",
    "+ 基于解析和模式匹配的处理方法，编程难点应该是语法部分的编写；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "语言模型现有两种定义：\n",
    "+ 一是基于马尔可夫假设来计算某个句子概率的模型；\n",
    "+ 二是用于预测下一个单词的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 语音识别、机器翻译等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 1-gram语言模式是假设各分词统计独立的n-gram模型，即每个分词出现的概率只与其自身有关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 优点：计算复杂度低，储存空间要求小，不会有严重的稀疏性问题；\n",
    "+ 缺点：没有利用各分词间的相关性，处理结果准确性不高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "+ 2-gram语言模型是假设各分词出现的概率只与其前一个分词有关的n-gram模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_grammar = '''\n",
    "my_hobby = noun verb activity\n",
    "noun = 我 | 俺\n",
    "verb = 爱好 | 喜欢 | 经常去\n",
    "activity = 看书 | 看电影 | 游泳 | 打游戏\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_grammar = '''\n",
    "compliment = begin noun verb adj end\n",
    "begin = 哦我的上帝啊， | 天哪,\n",
    "noun = 小洋\n",
    "verb = 真 | 好 | 多么\n",
    "adj = 棒 | 厉害 | 聪明 | 懂事 | 美丽 | 漂亮 | 帅气 | 迷人\n",
    "end = 啊！\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def generate(gram, target):\n",
    "    if target not in gram:\n",
    "        return target\n",
    "    \n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '\\n' else '\\n' for e in expaned if e != 'null'])  \n",
    "\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue   \n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'俺喜欢看书'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=create_grammar(first_grammar), target='my_hobby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哦我的上帝啊，小洋真帅气啊！'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=create_grammar(second_grammar), target='compliment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n, gram, target):\n",
    "    sen_list = []\n",
    "    for i in range(n):\n",
    "        sen_list.append(generate(gram,target))\n",
    "    return sen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['天哪,小洋好帅气啊！',\n",
       " '哦我的上帝啊，小洋真帅气啊！',\n",
       " '天哪,小洋真帅气啊！',\n",
       " '天哪,小洋真帅气啊！',\n",
       " '天哪,小洋好棒啊！',\n",
       " '哦我的上帝啊，小洋真聪明啊！',\n",
       " '哦我的上帝啊，小洋真厉害啊！',\n",
       " '哦我的上帝啊，小洋真迷人啊！',\n",
       " '天哪,小洋真漂亮啊！',\n",
       " '天哪,小洋真聪明啊！']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(10,create_grammar(second_grammar), target='compliment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>“犯我中华者，虽远必诛”，吴京比这句话还要意淫一百倍。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>脑子是个好东西，希望编剧们都能有。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>三星半，实打实的7分。第一集在爱国主旋律内部做着各种置换与较劲，但第二集才真正显露吴京的野心...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>开篇长镜头惊险大气引人入胜 结合了水平不俗的快剪下实打实的真刀真枪 让人不禁热血沸腾 特别弹...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>15/100吴京的冷峰在这部里即像成龙，又像杰森斯坦森，但体制外的同类型电影，主角总是代表个...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        link name  \\\n",
       "0   1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1   2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2   3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3   4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4   5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "5   6  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "6   7  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "7   8  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "8   9  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "9  10  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  \n",
       "5                        “犯我中华者，虽远必诛”，吴京比这句话还要意淫一百倍。    1  \n",
       "6                                  脑子是个好东西，希望编剧们都能有。    2  \n",
       "7  三星半，实打实的7分。第一集在爱国主旋律内部做着各种置换与较劲，但第二集才真正显露吴京的野心...    4  \n",
       "8  开篇长镜头惊险大气引人入胜 结合了水平不俗的快剪下实打实的真刀真枪 让人不禁热血沸腾 特别弹...    4  \n",
       "9  15/100吴京的冷峰在这部里即像成龙，又像杰森斯坦森，但体制外的同类型电影，主角总是代表个...    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取文本数据\n",
    "filename = '/Users/Zhu Tong/Desktop/NLP培训/nlp核心/5月13日 作业压缩包/作业文件/movie_comments.csv'\n",
    "content = pd.read_csv(filename)\n",
    "content.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步看了恶心想吐',\n",
       " '首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬2刻意做作的主旋律煽情显得如此不合时宜而又多余',\n",
       " '凭良心说好看到不像战狼1的续集完虐湄公河行动',\n",
       " '中二得很',\n",
       " '犯我中华者虽远必诛吴京比这句话还要意淫一百倍',\n",
       " '脑子是个好东西希望编剧们都能有',\n",
       " '三星半实打实的7分第一集在爱国主旋律内部做着各种置换与较劲但第二集才真正显露吴京的野心他终于抛弃李忠志了新增外来班底让硬件实力有机会和国际接轨开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶在理念上它甚至做到绣春刀2最想做到的那部分',\n",
       " '开篇长镜头惊险大气引人入胜结合了水平不俗的快剪下实打实的真刀真枪让人不禁热血沸腾特别弹簧床架挡炸弹空手接碎玻璃弹匣割喉等帅得飞起就算前半段铺垫节奏散漫主角光环开太大等也不怕作为一个中国人两个小时弥漫着中国强大得不可侵犯的氛围还是让那颗民族自豪心砰砰砰跳个不停',\n",
       " '15100吴京的冷峰在这部里即像成龙又像杰森斯坦森但体制外的同类型电影主角总是代表个人无能的政府需要求助于这些英雄才能解决难题体现的是个人的价值所以主旋律照抄这种模式实际上是有问题的我们以前嘲笑个人英雄主义却没想到捆绑爱国主义的全能战士更加难以下咽']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本清洗，获得纯文本\n",
    "comment = content['comment'].tolist()\n",
    "\n",
    "def token(string):\n",
    "    return re.findall('\\w+',string)\n",
    "\n",
    "comment_clean = [''.join(token(str(i))) for i in comment]\n",
    "comment_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行文本切词\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))\n",
    "\n",
    "TOKEN = []\n",
    "for i, line in enumerate(comment_clean):\n",
    "    if i%10000 == 0: print(i)\n",
    "    \n",
    "    if i > 200000: break\n",
    "    TOKEN += cut(line)\n",
    "\n",
    "TOKEN[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8815927600558224e-07"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义2-gram语言模型\n",
    "from collections import Counter\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "words_count_2 = Counter(TOKEN_2_GRAM)\n",
    "\n",
    "def prob_2(word1,word2):\n",
    "    if word1 + word2 in words_count_2:\n",
    "        return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)\n",
    "\n",
    "prob_2('我的','上帝')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 天哪,小洋真漂亮啊！ with Prb: 2.0232344303837095e-41\n",
      "sentence: 天哪,小洋多么迷人啊！ with Prb: 8.512907841726689e-44\n",
      "sentence: 天哪,小洋多么迷人啊！ with Prb: 8.512907841726689e-44\n",
      "sentence: 哦我的上帝啊，小洋多么美丽啊！ with Prb: 2.485595722656009e-59\n",
      "sentence: 哦我的上帝啊，小洋好聪明啊！ with Prb: 3.7283935839840135e-59\n",
      "sentence: 天哪,小洋好懂事啊！ with Prb: 7.094089868105574e-45\n",
      "sentence: 哦我的上帝啊，小洋真美丽啊！ with Prb: 1.739917005859206e-58\n",
      "sentence: 哦我的上帝啊，小洋多么懂事啊！ with Prb: 1.2427978613280045e-59\n",
      "sentence: 哦我的上帝啊，小洋真懂事啊！ with Prb: 1.2427978613280045e-59\n",
      "sentence: 哦我的上帝啊，小洋真美丽啊！ with Prb: 1.739917005859206e-58\n"
     ]
    }
   ],
   "source": [
    "# 输入先前定义的语言模型，计算句子概率\n",
    "def get_probability(sentence):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        probability = prob_2(word, next_)\n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro\n",
    "\n",
    "for i in range(10):\n",
    "    sen = generate(gram=create_grammar(second_grammar), target='compliment')\n",
    "    \n",
    "    print('sentence: {} with Prb: {}'.format(sen, get_probability(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天晚上我们一起看电影 is more possible\n",
      "---- 今天晚上我们一起看电影 with probility 4.7651748680747226e-26\n",
      "---- 我们今天晚上一起看电影 with probility 3.403696334339088e-27\n",
      "真是一部好作品 is more possible\n",
      "---- 真事一部好作品 with probility 2.446531143329004e-22\n",
      "---- 真是一部好作品 with probility 4.851545352164613e-15\n",
      "我爱看这部电影 is more possible\n",
      "---- 我爱看这部电影 with probility 2.5566562481692093e-16\n",
      "---- 这部电影爱看我 with probility 1.0226624992676838e-16\n",
      "动作电影来一部 is more possible\n",
      "---- 动作电影来一部 with probility 6.711671292573357e-16\n",
      "---- 电影动作来一部 with probility 1.3399415058256968e-17\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上我们一起看电影 我们今天晚上一起看电影\",\n",
    "    \"真事一部好作品 真是一部好作品\",\n",
    "    \"我爱看这部电影 这部电影爱看我\",\n",
    "    \"动作电影来一部 电影动作来一部\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = get_probablity(s1), get_probablity(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天哪,小洋真漂亮啊！ is the best generation.\n",
      "---- 天哪,小洋真漂亮啊！ with probability 2.0232344303837095e-41.\n",
      "---- 天哪,小洋真迷人啊！ with probability 4.256453920863344e-43.\n",
      "---- 天哪,小洋好迷人啊！ with probability 3.83080852877701e-43.\n",
      "---- 天哪,小洋好美丽啊！ with probability 1.135054378896892e-43.\n",
      "---- 天哪,小洋真聪明啊！ with probability 7.094089868105574e-45.\n",
      "---- 天哪,小洋好懂事啊！ with probability 7.094089868105574e-45.\n",
      "---- 哦我的上帝啊，小洋好棒啊！ with probability 2.658344625380601e-56.\n",
      "---- 哦我的上帝啊，小洋好厉害啊！ with probability 1.6181228154490615e-56.\n",
      "---- 哦我的上帝啊，小洋好帅气啊！ with probability 1.3919336046873648e-57.\n",
      "---- 哦我的上帝啊，小洋多么漂亮啊！ with probability 5.7168701621088215e-58.\n",
      "我喜欢打游戏 is the best generation.\n",
      "---- 我喜欢打游戏 with probability 7.332058345133814e-11.\n",
      "---- 我爱好打游戏 with probability 8.303576834806132e-14.\n",
      "---- 俺爱好游泳 with probability 8.303576834806132e-14.\n",
      "---- 我爱好打游戏 with probability 8.303576834806132e-14.\n",
      "---- 我爱好打游戏 with probability 8.303576834806132e-14.\n",
      "---- 我爱好看书 with probability 8.303576834806132e-14.\n",
      "---- 俺喜欢看电影 with probability 8.162397247898572e-15.\n",
      "---- 俺爱好看电影 with probability 9.929923659244006e-18.\n",
      "---- 我经常去打游戏 with probability 3.3498537645642425e-19.\n",
      "---- 俺经常去看电影 with probability 5.986047989221247e-21.\n"
     ]
    }
   ],
   "source": [
    "def generate_best(n, grammar, target): \n",
    "    gram = create_grammar(grammar)\n",
    "    sentences = generate_n(n, gram, target)\n",
    "    \n",
    "    sen_with_prob = []\n",
    "    \n",
    "    for sen in sentences:\n",
    "        prob = get_probability(sen)\n",
    "        sen_with_prob.append((sen,prob))\n",
    "    \n",
    "    sen_with_prob_sorted = sorted(sen_with_prob, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print('{} is the best generation.'.format(sen_with_prob_sorted[0][0]))\n",
    "    for i in range(n):\n",
    "        print('-'*4 + ' {} with probability {}.'.format(sen_with_prob_sorted[i][0],sen_with_prob_sorted[i][1]))\n",
    "\n",
    "generate_best(10,second_grammar,'compliment')\n",
    "generate_best(10,first_grammar,'my_hobby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "+ 模型存在问题：语法模型简单，生成的句子内容比较单一；\n",
    "+ 提升方法：提升语法模型的复杂度，使之可以生成内容更丰富的句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
